{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "\n",
    "seq_len = 40\n",
    "step = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/text_corpus.txt', 'r')\n",
    "text = file.read().lower().strip()\n",
    "to_replace = ['\\n', '\\t', '\\xa0',\n",
    " '¡', '¢', '£', '§', '«', '°', '±', '´', '·', '»', '¼', '½', '¾', '¿', '×', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è',\n",
    " 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ñ', 'ò', 'ó', 'ô', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ÿ', 'š', '–', '—', '‘', '’', '“', '”', \n",
    " '„', '†', '•', '…', '‹', '›','¹', 'õ', 'ž','ð',  '®', '¯', '²', 'µ', 'œ',\n",
    "             '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "             ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`',\n",
    "             '{', '|', '}', '~', '¥', '‚', '€']\n",
    "for tr in to_replace:\n",
    "    text = text.replace(tr, '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the exclamation mark british english or exclamation point some dialects of american english is a punctuation mark usually used after an interjection or exclamation to indicate strong feelings or high volume shouting or show emphasis and often marks the end of a sentence example watch out similarly a bare exclamation mark with nothing before or after is often used in warning signsother uses includegraphically the exclamation mark is represented as a full stop point with a vertical line above one theory of its origin is that it is derived from a latin exclamation of joy io the modern graphical representation is believed to have been born in the middle ages medieval copyists wrote the latin word io at the end of a sentence to indicate joy the word io meant hurray over time the i moved above the o and the o became smaller becoming a pointthe exclamation mark was first introduced into english printing in the 15th century to show emphasis and was called the sign of admiration or exclamation \n",
      "14873320\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "unique_chars = sorted(list(set(text)))\n",
    "print(len(unique_chars))\n",
    "num_chars = len(unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] "
     ]
    }
   ],
   "source": [
    "print(unique_chars, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_char(idx, size):\n",
    "    oh = np.zeros((size))\n",
    "    oh[idx] = 1\n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_pred(pred, top_n = 1):\n",
    "    nth_top = np.sort(pred)[-top_n]\n",
    "    idx = np.argwhere(pred == nth_top)\n",
    "    return idx[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0                                # maybe start with 1\n",
    "char_to_idx = {}\n",
    "idx_to_char = {}\n",
    "for char in unique_chars:\n",
    "    char_to_idx[char] = i\n",
    "    idx_to_char[i] = char\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "t = one_hot_char(char_to_idx[' '], num_chars)\n",
    "print(t)\n",
    "print(char_to_idx[' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_model():\n",
    "    inputs = Input(shape = (seq_len, num_chars))\n",
    "    X = LSTM(128, return_sequences = True)(inputs)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128)(X)\n",
    "    X = Dense(num_chars, activation = 'softmax')(X)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "# pad_vector = [0]*num_chars\n",
    "# pad_vector[0] = 1\n",
    "\n",
    "for i in range(0, 100000 - seq_len, step):\n",
    "#     random_len = np.random.randint(0, seq_len)\n",
    "#     to_pad = seq_len - random_len\n",
    "#     pad_vector = [pad_vector] * to_pad\n",
    "#     temp = text[i:i+random_len]\n",
    "    temp = text[i:i+seq_len]\n",
    "#     y = one_hot_char(char_to_idx[text[i+random_len]], num_chars)\n",
    "    y = one_hot_char(char_to_idx[text[i+seq_len]], num_chars)\n",
    "    x = [one_hot_char(char_to_idx[char], num_chars) for char in temp]\n",
    "#     print(temp , ' : ', text[i+random_len])\n",
    "#     print(temp , ' : ', text[i+seq_len])\n",
    "\n",
    "#     X_train.append([one_hot_char(char_to_idx[char], num_chars) for char in temp] + pad_vector)\n",
    "    X_train.append(x)\n",
    "    Y_train.append(y)\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33320, 40, 37)\n",
      "(33320, 37)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = char_model()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33320/33320 [==============================] - 144s 4ms/step - loss: 2.7097 - acc: 0.2231\n",
      "Epoch 2/10\n",
      "33320/33320 [==============================] - 143s 4ms/step - loss: 2.3070 - acc: 0.3163\n",
      "Epoch 3/10\n",
      "33320/33320 [==============================] - 143s 4ms/step - loss: 2.1471 - acc: 0.3615\n",
      "Epoch 4/10\n",
      "33320/33320 [==============================] - 142s 4ms/step - loss: 2.0419 - acc: 0.3925\n",
      "Epoch 5/10\n",
      "33320/33320 [==============================] - 142s 4ms/step - loss: 1.9567 - acc: 0.4173\n",
      "Epoch 6/10\n",
      "33320/33320 [==============================] - 142s 4ms/step - loss: 1.8863 - acc: 0.4391\n",
      "Epoch 7/10\n",
      "33320/33320 [==============================] - 142s 4ms/step - loss: 1.8250 - acc: 0.4566\n",
      "Epoch 8/10\n",
      "33320/33320 [==============================] - 142s 4ms/step - loss: 1.7654 - acc: 0.4716\n",
      "Epoch 9/10\n",
      "33320/33320 [==============================] - 143s 4ms/step - loss: 1.7143 - acc: 0.4882\n",
      "Epoch 10/10\n",
      "33320/33320 [==============================] - 142s 4ms/step - loss: 1.6673 - acc: 0.4989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26dc5e67390>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 10, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_till_space(sequence, model):\n",
    "    original = sequence.lower()\n",
    "    final = []\n",
    "    for i in range(1, 6):\n",
    "        output = \"\"\n",
    "        sequence = [[one_hot_char(char_to_idx[char], num_chars) for char in original]]\n",
    "        pred = model.predict(np.array(sequence))[0]\n",
    "        y = one_hot_char(reverse_pred(pred, top_n = i), num_chars)\n",
    "        sequence[0].append(y)\n",
    "        del sequence[0][0]\n",
    "        y = idx_to_char[reverse_pred(pred, top_n = i)]\n",
    "        output += y\n",
    "        while True:\n",
    "            pred = model.predict(np.array(sequence))[0]\n",
    "            y = one_hot_char(reverse_pred(pred), num_chars)\n",
    "            sequence[0].append(y)\n",
    "            del sequence[0][0]\n",
    "            y = idx_to_char[reverse_pred(pred)]\n",
    "            if y == ' ':\n",
    "                break\n",
    "            output +=y\n",
    "        final.append(output)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are other martyrs used by country  : ['be', 'of', 'to', 'some', 'and']\n",
      "War Thunder is the most comprehensive ga : ['s', 'nd', 've', 'me', 'le']\n",
      "They thought it was all over the nation  : ['of', 'a', 'in', 'the', 'for']\n",
      "highly detailed and personalized aviatio : ['n', ' a', 'l', 'r', 'u']\n"
     ]
    }
   ],
   "source": [
    "test = ['There are other martyrs used by country ',\n",
    "        'War Thunder is the most comprehensive ga',\n",
    "        'They thought it was all over the nation ',\n",
    "        'highly detailed and personalized aviatio']\n",
    "for phrase in test:\n",
    "    results = predict_till_space(phrase, model)\n",
    "    print(phrase, \":\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
