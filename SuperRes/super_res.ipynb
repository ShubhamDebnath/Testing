{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.pyplot import imshow, plot, show\n",
    "from keras.layers import Conv2D, Add, BatchNormalization, Input, Lambda, Multiply\n",
    "from keras.backend import tensorflow_backend as K\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.losses import mean_squared_error\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please set img_dir to your pictures folder first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_scale = 0.1\n",
    "scale = 2\n",
    "batch_size = 20\n",
    "validation_size = int(0.25 * batch_size)\n",
    "input_shape = (128, 128, 3)\n",
    "output_shape = (256, 256, 3)\n",
    "# img_dir = 'DIV2K_train_HR/'\n",
    "img_dir = 'VOCdevkit/VOC2012/JPEGImages/'\n",
    "image_list = os.listdir(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(current_batch = 0):\n",
    "    \n",
    "    start = current_batch * batch_size\n",
    "    end = (current_batch+1) * batch_size\n",
    "    train_y = [cv2.imread(os.path.join(img_dir, i), 1) for i in image_list[start:end]]\n",
    "    test_x = [cv2.resize(i, input_shape[:2]) for i in train_y[-validation_size:]]\n",
    "    test_y = [cv2.resize(i, output_shape[:2]) for i in train_y[-validation_size:]]\n",
    "    train_x = [cv2.resize(i, input_shape[:2]) for i in train_y[:-validation_size]]\n",
    "    train_y = [cv2.resize(i, output_shape[:2]) for i in train_y[:-validation_size]]\n",
    "#     print(len(train_x))\n",
    "#     print(len(train_y))\n",
    "    \n",
    "    return np.array(train_x), np.array(train_y), np.array(test_x), np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st implementaion of Pixel Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Borrowed from https://github.com/tetrachrome/subpixel\n",
    "Used for subpixel phase shifting after deconv operations\n",
    "\"\"\"\n",
    "def _phase_shift(I, r):\n",
    "    bsize, a, b, c = I.get_shape().as_list()\n",
    "    bsize = Lambda( lambda tensor: tf.shape(tensor)[0])(I) # Handling Dimension(None) type for undefined batch dim\n",
    "    X = Lambda( lambda tensor: tf.reshape(tensor, (bsize, a, b, r, r)))(I)\n",
    "    X = Lambda( lambda tensor: tf.transpose(tensor, (0, 1, 2, 4, 3)))(X)  # bsize, a, b, 1, 1\n",
    "    X = Lambda( lambda tensor: tf.split(tensor, a, 1))(X) #K.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "    X = Lambda( lambda tensor: tf.concat([tf.squeeze(x, axis=1) for x in tensor],2))(X)  # bsize, b, a*r, r\n",
    "    X = Lambda( lambda tensor: tf.split(tensor, b, 1))(X) #K.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "    X = Lambda( lambda tensor: tf.concat([tf.squeeze(x, axis=1) for x in tensor],2))(X)  # bsize, a*r, b*r\n",
    "    return Lambda(lambda tensor: tf.reshape(tensor, (bsize, a*r, b*r, 1)))(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Borrowed from https://github.com/tetrachrome/subpixel\n",
    "Used for subpixel phase shifting after deconv operations\n",
    "\"\"\"\n",
    "def PS(X, r, color=False):\n",
    "    if color:\n",
    "        Xc = Lambda( lambda tensor: tf.split(tensor, 3, 3))(X)\n",
    "        X = Lambda( lambda tensor: tf.concat([_phase_shift(x, r) for x in tensor],3))(Xc)\n",
    "    else:\n",
    "        X = _phase_shift(X, r)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd implementaion of Pixel Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubpixelConv2D(input_shape, scale=4):\n",
    "    \"\"\"\n",
    "    Borrowed from https://github.com/twairball/keras-subpixel-conv/blob/master/subpixel.py\n",
    "    Keras layer to do subpixel convolution.\n",
    "    NOTE: Tensorflow backend only. Uses tf.depth_to_space\n",
    "    Ref:\n",
    "        [1] Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\n",
    "            Shi et Al.\n",
    "            https://arxiv.org/abs/1609.05158\n",
    "    :param input_shape: tensor shape, (batch, height, width, channel)\n",
    "    :param scale: upsampling scale. Default=4\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # upsample using depth_to_space\n",
    "    def subpixel_shape(input_shape):\n",
    "        dims = [input_shape[0],\n",
    "                input_shape[1] * scale,\n",
    "                input_shape[2] * scale,\n",
    "                int(input_shape[3] / (scale ** 2))]\n",
    "        output_shape = tuple(dims)\n",
    "        return output_shape\n",
    "\n",
    "    def subpixel(x):\n",
    "        return tf.depth_to_space(x, scale)\n",
    "\n",
    "\n",
    "    return Lambda(subpixel, output_shape=subpixel_shape, name='subpixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Model\n",
    "just a few conv layers as res blocks and pixel shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_model(input_shape):\n",
    "    \n",
    "    inputs = Input(shape = input_shape)\n",
    "    conv_1 = Conv2D(64, (3, 3), strides = (1, 1), padding = 'same', activation = 'relu', name = 'conv_1_1')(inputs)\n",
    "    \n",
    "    ## Just for using in the for loop\n",
    "    X = conv_1\n",
    "    \n",
    "    ## Res Blocks\n",
    "    for i in range(2, 10):\n",
    "        X = Conv2D(64, (3, 3), strides = (1, 1), padding = 'same', activation = 'relu', name = 'conv_{}_1'.format(i))(X)\n",
    "        X1 = Conv2D(64, (3, 3), strides = (1, 1), padding = 'same', name = 'conv_{}_2'.format(i))(X)\n",
    "        X1 = Lambda( lambda tensor: tensor * res_scale, name = 'multiply_{}'.format(i))(X1)\n",
    "        X = Add()([X, X1])\n",
    "    \n",
    "    ## Adding result of Res Blocks with output of 1st layer\n",
    "    X = Add()([X, conv_1])\n",
    "    \n",
    "    ## This portion is for upsampling, keeping r = 2\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), padding = 'same', activation = 'relu', name = 'conv_10_1')(X)\n",
    "    \n",
    "    ## 1st implementation of Pixel Shuffle\n",
    "    X = Conv2D(3*(scale ** 2), (3, 3), strides = (1, 1), padding = 'same', activation = 'relu', name = 'conv_11_1')(X)\n",
    "    X = PS(X, scale, color = True)\n",
    "\n",
    "    ## 2nd implementaion of Pixel Shuffle\n",
    "#     X = Conv2D(64 * (scale ** 2), (3, 3), strides = (1, 1), padding = 'same', activation = 'relu', name = 'conv_11_1')(X)\n",
    "#     X = SubpixelConv2D(X.shape, scale = scale)(X)\n",
    "    \n",
    "    ## Just because Jeremy Howard said it works\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    ## One final conv layer, to bring back to required size\n",
    "    X = Conv2D(3, (3, 3), strides = (1, 1), padding = 'same', name = 'conv_12_1')(X)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Model\n",
    "loading up vgg16 from keras.applications and sending some its layers as output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_model():\n",
    "    \n",
    "    base_model = VGG16(include_top = False, weights = 'imagenet', input_shape = output_shape)\n",
    "#     vgg.load_model('pre_trained/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "\n",
    "    ## listing all the layers required for perceptual loss as mentioned in EDSR\n",
    "    layers_required = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3']\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Model(inputs = base_model.input, outputs = [base_model.get_layer(i).output for i in layers_required])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Model\n",
    "combining the transformation model and loss model into a single one, and using MSE loss between output of loss model om generated and actual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model():\n",
    "    l_model = loss_model()\n",
    "    t_model = transformation_model(input_shape)\n",
    "    loss_model_outputs = l_model(t_model.output)\n",
    "    model = Model(inputs = t_model.input, outputs = loss_model_outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = full_model()\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "Caliing fit funtion iteratively for all the batches because I can't load up all the images at once in main memory or gpu memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fba8d4b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " ******************** \n",
      "\n",
      "\n",
      "\n",
      "current batch number:  1 out of  85\n"
     ]
    }
   ],
   "source": [
    "num_batches = len(image_list) // batch_size\n",
    "l_model = loss_model()\n",
    "\n",
    "for i in range(num_batches):\n",
    "    print('\\n\\n\\n', '*'*20, '\\n\\n\\n')\n",
    "    print('current batch number: ', i, 'out of ', num_batches)\n",
    "    train_x, train_y, test_x, test_y = get_data(i)\n",
    "    loss_train_y = l_model.predict(train_y)\n",
    "    loss_test_y = l_model.predict(test_y)\n",
    "    model.fit(x = train_x, y = loss_train_y, batch_size = 16, epochs = 200, validation_data = (test_x, loss_test_y))\n",
    "    \n",
    "    ## This code is just to plot the losses, you may comment all this and un-comment the above model.fit() call\n",
    "#     history = model.fit(x = train_x, y = loss_train_y, batch_size = 16, epochs = 200, verbose = 0, validation_data = (test_x, loss_test_y))\n",
    "#     clear_output()\n",
    "#     plot(history.history['loss'])\n",
    "#     show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of useful code\n",
    "### below is just some code snippets left from experimentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(loss[3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = get_data(0)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptual_loss(y_true, y_pred):\n",
    "    l_model = loss_model(y_true)\n",
    "    actual = l_model.predict(y_true)\n",
    "    l_model = loss_model(y_pred)\n",
    "    generated = l_model.predict(y_pred)\n",
    "    mse_loss = mean_squared_error(actual, generated)\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_model = loss_model()\n",
    "l_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_model = transformation_model(input_shape)\n",
    "t_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
